from django.shortcuts import render
import gspread
from oauth2client.service_account import ServiceAccountCredentials
from tinkoff.invest import Client, CandleInterval
from tinkoff.invest.utils import quotation_to_decimal
from datetime import datetime, timedelta
import pytz
import time
from gspread.utils import rowcol_to_a1
import re
import traceback
from dateutil import parser as dateparser
import pandas as pd
import numpy as np
import os
import json
from django.conf import settings
from dotenv import load_dotenv

load_dotenv()

# === –ù–ê–°–¢–†–û–ô–ö–ò ===

GOOGLE_CREDENTIALS_FILE = os.getenv("GOOGLE_CREDENTIALS_PATH")
SPREADSHEET_NAME = os.getenv("SPREADSHEET_NAME")
TOKEN = os.getenv("TINKOFF_TOKEN")
DAYS = 20
MAX_SHEET_ROWS = 1000
MAX_EXISTING_ROWS_TO_COMPARE = 2000
tz = pytz.timezone("Europe/Moscow")
MAX_RETRIES = 5
DELAY = 10

def safe_get_cell(sheet, row, col, retries=5, delay=5):
    for attempt in range(1, retries + 1):
        try:
            val = sheet.cell(row, col).value
            print(f"safe_get_cell: –ü–æ–ª—É—á–∏–ª–∏ –∑–Ω–∞—á–µ–Ω–∏–µ —Å ({row},{col}): {val}")
            return val
        except Exception as e:
            print(f"safe_get_cell: –û—à–∏–±–∫–∞ –¥–æ—Å—Ç—É–ø–∞ –∫ —è—á–µ–π–∫–µ ({row},{col}), –ø–æ–ø—ã—Ç–∫–∞ {attempt}: {e}")
            time.sleep(delay)
    print(f"safe_get_cell: –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏–µ —Å ({row},{col}) –ø–æ—Å–ª–µ {retries} –ø–æ–ø—ã—Ç–æ–∫")
    return None

def parse_range_bounds(cell_range):
    match = re.search(r'([A-Z]+)(\d+):[A-Z]+(\d+)', cell_range)
    if match:
        start_row = int(match.group(2))
        end_row = int(match.group(3))
        print(f"parse_range_bounds: –î–∏–∞–ø–∞–∑–æ–Ω —Å—Ç—Ä–æ–∫: {start_row} - {end_row}")
        return (start_row, end_row)
    print(f"parse_range_bounds: –ù–µ —É–¥–∞–ª–æ—Å—å —Ä–∞—Å–ø–∞—Ä—Å–∏—Ç—å –¥–∏–∞–ø–∞–∑–æ–Ω: {cell_range}")
    return (None, None)

def ensure_enough_rows(sheet, required_row):
    current_rows = len(sheet.get_all_values())
    if required_row > current_rows:
        print(f"ensure_enough_rows: –î–æ–±–∞–≤–ª—è–µ–º {required_row - current_rows} —Å—Ç—Ä–æ–∫ –¥–æ {required_row}")
        sheet.add_rows(required_row - current_rows)
    else:
        print(f"ensure_enough_rows: –°—Ç—Ä–æ–∫ –¥–æ—Å—Ç–∞—Ç–æ—á–Ω–æ ({current_rows} >= {required_row})")

def run_parser():
    output = []
    try:
        print("run_parser: –ù–∞—á–∏–Ω–∞–µ–º –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é –≤ Google Sheets...")
        output.append("–ù–∞—á–∏–Ω–∞–µ–º –∞–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—é –≤ Google Sheets...")
        scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
        creds = ServiceAccountCredentials.from_json_keyfile_name(GOOGLE_CREDENTIALS_FILE, scope)
        client_gs = gspread.authorize(creds)
        sheet = client_gs.open(SPREADSHEET_NAME).sheet1
        output.append("–£—Å–ø–µ—à–Ω–æ –∞–≤—Ç–æ—Ä–∏–∑–æ–≤–∞–Ω—ã –∏ –ø–æ–ª—É—á–∏–ª–∏ –¥–æ—Å—Ç—É–ø –∫ —Ç–∞–±–ª–∏—Ü–µ")

        tickers_row = 4
        figi_row = 5
        start_col = 3
        num_tickers = 41

        tickers, figis, cols_for_data = [], [], []

        print(f"run_parser: –ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏–∑ {num_tickers} —Ç–∏–∫–µ—Ä–æ–≤ –∏ FIGI...")
        output.append(f"–ü–æ–ª—É—á–∞–µ–º —Å–ø–∏—Å–æ–∫ –∏–∑ {num_tickers} —Ç–∏–∫–µ—Ä–æ–≤ –∏ FIGI...")

        for i in range(num_tickers):
            col = start_col + i * 2
            ticker = safe_get_cell(sheet, tickers_row, col)
            time.sleep(0.6)
            figi = safe_get_cell(sheet, figi_row, col)
            time.sleep(0.6)
            if ticker and figi:
                tickers.append(ticker.strip())
                figis.append(figi.strip())
                cols_for_data.append((col, col + 1))

        output.append(f"–ù–∞–π–¥–µ–Ω–æ —Ç–∏–∫–µ—Ä–æ–≤: {len(tickers)}")
        print(f"run_parser: –ù–∞–π–¥–µ–Ω–æ —Ç–∏–∫–µ—Ä–æ–≤: {len(tickers)}")

        with Client(TOKEN) as client_invest:
            for ticker, figi, (date_col, price_col) in zip(tickers, figis, cols_for_data):
                output.append(f"‚è≥ –ó–∞–≥—Ä—É–∑–∫–∞ –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {ticker} (FIGI: {figi})")
                print(f"run_parser: –ù–∞—á–∏–Ω–∞–µ–º –∑–∞–≥—Ä—É–∑–∫—É –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {ticker} (FIGI: {figi})")

                candles_data = []

                all_dates = sheet.col_values(date_col)[7:]  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
                print(f"run_parser: –í —Ç–∞–±–ª–∏—Ü–µ –¥–ª—è {ticker} –Ω–∞–π–¥–µ–Ω–æ {len(all_dates)} –∑–∞–ø–∏—Å–µ–π –¥–∞—Ç")

                last_datetime = None
                if all_dates:
                    try:
                        parsed_datetimes = [dateparser.parse(d) for d in all_dates if d]
                        if parsed_datetimes:
                            last_datetime = max(parsed_datetimes)
                        print(f"run_parser: –ü–æ—Å–ª–µ–¥–Ω–∏–π datetime –≤ —Ç–∞–±–ª–∏—Ü–µ –¥–ª—è {ticker}: {last_datetime}")
                    except Exception as e:
                        print(f"run_parser: –û—à–∏–±–∫–∞ –ø–∞—Ä—Å–∏–Ω–≥–∞ –¥–∞—Ç—ã –¥–ª—è {ticker}: {e}")

                now = datetime.now(tz)

                if last_datetime is None:
                    start_date = now - timedelta(days=DAYS)
                    start_from = tz.localize(datetime(start_date.year, start_date.month, start_date.day, 10, 0))
                else:
                    # –ù–∞—á–∏–Ω–∞–µ–º —Å –ø–æ—Å–ª–µ–¥–Ω–µ–≥–æ —Å–æ—Ö—Ä–∞–Ω—ë–Ω–Ω–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ + 5 –º–∏–Ω—É—Ç
                    start_from = last_datetime + timedelta(minutes=5)
                    if start_from.tzinfo is None:
                        start_from = tz.localize(start_from)

                current_dt = start_from

                while current_dt < now:
                    day_start = tz.localize(datetime(current_dt.year, current_dt.month, current_dt.day, 10, 0))
                    day_end = tz.localize(datetime(current_dt.year, current_dt.month, current_dt.day, 18, 45))

                    query_from = current_dt if current_dt.date() == start_from.date() else day_start
                    query_to = day_end

                    try:
                        candles = client_invest.market_data.get_candles(
                            figi=figi,
                            from_=query_from,
                            to=query_to,
                            interval=CandleInterval.CANDLE_INTERVAL_5_MIN
                        ).candles

                        for candle in candles:
                            candle_time = candle.time.astimezone(tz)
                            close_price = float(quotation_to_decimal(candle.close))
                            candles_data.append([candle_time.strftime('%Y-%m-%d %H:%M:%S'), close_price])

                        print(f"run_parser: –ü–æ–ª—É—á–µ–Ω–æ {len(candles)} —Å–≤–µ—á–µ–π –¥–ª—è {ticker} –∑–∞ {current_dt.date()}")
                        time.sleep(0.15)
                    except Exception as e:
                        err_msg = f"‚ùå –û—à–∏–±–∫–∞ {ticker} {current_dt.date()}: {e}"
                        output.append(err_msg)
                        print(err_msg)

                    current_dt = day_start + timedelta(days=1)

                candles_data.sort(key=lambda x: x[0])

                last_dates = all_dates[-MAX_EXISTING_ROWS_TO_COMPARE:]
                existing_dates = set(last_dates)
                new_candles = [row for row in candles_data if row[0] not in existing_dates]

                if not new_candles:
                    output.append(f"‚úÖ –ù–µ—Ç –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {ticker}")
                    print(f"run_parser: –ù–µ—Ç –Ω–æ–≤—ã—Ö –¥–∞–Ω–Ω—ã—Ö –¥–ª—è {ticker}")
                    continue

                first_free_row = len(all_dates) + 8
                dates = [[row[0]] for row in new_candles]
                prices = [[row[1]] for row in new_candles]

                date_range = f"{rowcol_to_a1(first_free_row, date_col)}:{rowcol_to_a1(first_free_row + len(dates) - 1, date_col)}"
                price_range = f"{rowcol_to_a1(first_free_row, price_col)}:{rowcol_to_a1(first_free_row + len(prices) - 1, price_col)}"

                _, date_end_row = parse_range_bounds(date_range)
                if date_end_row:
                    ensure_enough_rows(sheet, date_end_row)

                for attempt in range(1, MAX_RETRIES + 1):
                    try:
                        sheet.update(range_name=date_range, values=dates)
                        sheet.update(range_name=price_range, values=prices)
                        output.append(f"‚úÖ –î–æ–±–∞–≤–ª–µ–Ω–æ {len(new_candles)} —Å–≤–µ—á–µ–π –¥–ª—è {ticker}")
                        print(f"run_parser: –£—Å–ø–µ—à–Ω–æ –∑–∞–ø–∏—Å–∞–Ω–æ {len(new_candles)} –Ω–æ–≤—ã—Ö —Å–≤–µ—á–µ–π –¥–ª—è {ticker}")
                        break
                    except Exception as e:
                        err_msg = f"‚ùå –û—à–∏–±–∫–∞ –∑–∞–ø–∏—Å–∏ {ticker}, –ø–æ–ø—ã—Ç–∫–∞ {attempt}: {e}"
                        output.append(err_msg)
                        print(err_msg)
                        time.sleep(DELAY)
                else:
                    output.append(f"üö´ –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è {ticker}")
                    print(f"run_parser: –ù–µ —É–¥–∞–ª–æ—Å—å –∑–∞–ø–∏—Å–∞—Ç—å –¥–∞–Ω–Ω—ã–µ –¥–ª—è {ticker} –ø–æ—Å–ª–µ {MAX_RETRIES} –ø–æ–ø—ã—Ç–æ–∫")

    except Exception as e:
        err_trace = traceback.format_exc()
        output.append("‚ùå –û–±—â–∞—è –æ—à–∏–±–∫–∞:\n" + err_trace)
        print(f"run_parser: –û–±—â–∞—è –æ—à–∏–±–∫–∞:\n{err_trace}")

    return "\n".join(output)
def home(request):
    message = ""
    correlation_data = []
    growth_data = []

    print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] –ü–æ–ª—É—á–µ–Ω {request.method} –∑–∞–ø—Ä–æ—Å –Ω–∞ /home/")

    if request.method == 'POST':
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ‚ñ∂Ô∏è –ó–∞–ø—É—Å–∫–∞–µ–º –ø–∞—Ä—Å–µ—Ä...")
        message = run_parser()  # —Ç–≤–æ—è —Ñ—É–Ω–∫—Ü–∏—è –ø–∞—Ä—Å–∏–Ω–≥–∞, –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç —Å—Ç—Ä–æ–∫—É
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] ‚úÖ –ü–∞—Ä—Å–µ—Ä –∑–∞–≤–µ—Ä—à–µ–Ω.")
    else:
        print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] GET –∑–∞–ø—Ä–æ—Å ‚Äî –ø–∞—Ä—Å–µ—Ä –Ω–µ –∑–∞–ø—É—Å–∫–∞–µ—Ç—Å—è.")

    current_dir = os.path.dirname(os.path.abspath(__file__))

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏
    correlation_file = os.path.join(current_dir, 'correlations.json')
    if os.path.exists(correlation_file):
        try:
            with open(correlation_file, 'r', encoding='utf-8') as f:
                all_correlations = json.load(f)
            filtered = [c for c in all_correlations if c.get('correlation') is not None]
            sorted_corr = sorted(filtered, key=lambda x: abs(x['correlation']), reverse=True)
            correlation_data = sorted_corr[:10]
            print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] –ó–∞–≥—Ä—É–∂–µ–Ω–æ {len(correlation_data)} —Ç–æ–ø –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–π.")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ correlations.json: {e}")
    else:
        print(f"‚ö†Ô∏è –§–∞–π–ª correlations.json –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏: {correlation_file}")

    # –ó–∞–≥—Ä—É–∂–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ —Ä–æ—Å—Ç—É/–ø–∞–¥–µ–Ω–∏—é
    growth_file = os.path.join(current_dir, 'growth.json')
    if os.path.exists(growth_file):
        try:
            with open(growth_file, 'r', encoding='utf-8') as f:
                growth_all = json.load(f)

            # –§–∏–ª—å—Ç—Ä—É–µ–º —Ç–æ–ª—å–∫–æ —Å —á–∏—Å–ª–æ–≤—ã–º —Ä–æ—Å—Ç–æ–º
            growth_all = [g for g in growth_all if g.get('growth_percent') is not None]

            # –õ–∏–¥–µ—Ä—ã —Ä–æ—Å—Ç–∞ ‚Äî top 5 –ø–æ —É–±—ã–≤–∞–Ω–∏—é —Ä–æ—Å—Ç–∞ (>0)
            leaders_up = sorted(
                [g for g in growth_all if g['growth_percent'] > 0],
                key=lambda x: x['growth_percent'],
                reverse=True
            )[:5]

            # –õ–∏–¥–µ—Ä—ã –ø–∞–¥–µ–Ω–∏—è ‚Äî top 5 –ø–æ –≤–æ–∑—Ä–∞—Å—Ç–∞–Ω–∏—é —Ä–æ—Å—Ç–∞ (<0)
            leaders_down = sorted(
                [g for g in growth_all if g['growth_percent'] < 0],
                key=lambda x: x['growth_percent']
            )[:5]

            growth_data = {
                'leaders_up': leaders_up,
                'leaders_down': leaders_down
            }

            print(f"[{datetime.now().strftime('%Y-%m-%d %H:%M:%S')}] –ó–∞–≥—Ä—É–∂–µ–Ω–æ –ª–∏–¥–µ—Ä–æ–≤ —Ä–æ—Å—Ç–∞ –∏ –ø–∞–¥–µ–Ω–∏—è.")
        except Exception as e:
            print(f"‚ö†Ô∏è –û—à–∏–±–∫–∞ –ø—Ä–∏ —á—Ç–µ–Ω–∏–∏ growth.json: {e}")
    else:
        print(f"‚ö†Ô∏è –§–∞–π–ª growth.json –Ω–µ –Ω–∞–π–¥–µ–Ω –ø–æ –ø—É—Ç–∏: {growth_file}")

    return render(request, 'parserapp/home.html', {
        'message': message,
        'top_correlations': correlation_data,
        'growth_data': growth_data,
    })

def get_prices_df(sheet, date_col, price_col):
    """
    –ü–æ–ª—É—á–∞–µ–º DataFrame —Å –¥–∞—Ç–∞–º–∏ (index) –∏ —Ü–µ–Ω–∞–º–∏ –∏–∑ –ª–∏—Å—Ç–∞ Google Sheets
    """
    dates = sheet.col_values(date_col)[7:]  # –ø—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏
    prices = sheet.col_values(price_col)[7:]
    data = []
    for d, p in zip(dates, prices):
        if d and p:
            try:
                dt = dateparser.parse(d)
                price = float(p)
                data.append((dt, price))
            except Exception:
                continue
    df = pd.DataFrame(data, columns=['datetime', 'price'])
    df.set_index('datetime', inplace=True)
    return df.sort_index()

def find_ticker_columns(sheet, ticker):
    """
    –ù–∞—Ö–æ–¥–∏—Ç —Å—Ç–æ–ª–±—Ü—ã —Å –¥–∞—Ç–∞–º–∏ –∏ —Ü–µ–Ω–∞–º–∏ –ø–æ —Ç–∏–∫–µ—Ä—É
    –í–æ–∑–≤—Ä–∞—â–∞–µ—Ç (date_col, price_col) –∏–ª–∏ (None, None)
    """
    tickers_row = 4
    start_col = 3
    num_tickers = 41
    for i in range(num_tickers):
        col = start_col + i * 2
        cell = safe_get_cell(sheet, tickers_row, col)
        if cell and cell.strip().lower() == ticker.strip().lower():
            return (col, col + 1)
    return (None, None)


# –ü—Ä–∞–≤–∏–ª—å–Ω–æ –¥–∞–µ—Ç –¥–∞–Ω–Ω—ã–µ –ø–æ—Å–ª–µ–¥–Ω–∏—Ö 1000 —Å—Ç—Ä–æ–∫
def correlation_view(request):
    message = ""
    correlation = None 
    if request.method == 'POST':
        ticker1 = request.POST.get('ticker1', '').strip().upper()
        ticker2 = request.POST.get('ticker2', '').strip().upper()

        if ticker1 and ticker2:
            try:
                # –ê–≤—Ç–æ—Ä–∏–∑–∞—Ü–∏—è Google Sheets
                scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
                creds = ServiceAccountCredentials.from_json_keyfile_name(GOOGLE_CREDENTIALS_FILE, scope)
                client_gs = gspread.authorize(creds)
                sheet = client_gs.open(SPREADSHEET_NAME).sheet1

                # –ü–æ–∏—Å–∫ —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è —Ç–∏–∫–µ—Ä–∞ 1
                date_col1, price_col1 = find_ticker_columns(sheet, ticker1)
                # –ü–æ–∏—Å–∫ —Å—Ç–æ–ª–±—Ü–æ–≤ –¥–ª—è —Ç–∏–∫–µ—Ä–∞ 2
                date_col2, price_col2 = find_ticker_columns(sheet, ticker2)

                if None in (date_col1, price_col1):
                    message = f"–¢–∏–∫–µ—Ä {ticker1} –Ω–µ –Ω–∞–π–¥–µ–Ω."
                elif None in (date_col2, price_col2):
                    message = f"–¢–∏–∫–µ—Ä {ticker2} –Ω–µ –Ω–∞–π–¥–µ–Ω."
                else:
                    values = sheet.get_all_values()
                    rows = values[7:]  # –ü—Ä–æ–ø—É—Å–∫–∞–µ–º –∑–∞–≥–æ–ª–æ–≤–∫–∏

                    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –ø–µ—Ä–≤–æ–º—É —Ç–∏–∫–µ—Ä—É
                    data1 = []
                    for row in rows:
                        if len(row) <= price_col1:
                            continue
                        d1 = row[date_col1].strip()
                        p1 = row[price_col1].strip()
                        if d1 and p1:
                            data1.append((d1, p1))
                    last_data1 = data1[-1000:]

                    # –ü–æ–ª—É—á–∞–µ–º –¥–∞–Ω–Ω—ã–µ –ø–æ –≤—Ç–æ—Ä–æ–º—É —Ç–∏–∫–µ—Ä—É
                    data2 = []
                    for row in rows:
                        if len(row) <= price_col2:
                            continue
                        d2 = row[date_col2].strip()
                        p2 = row[price_col2].strip()
                        if d2 and p2:
                            data2.append((d2, p2))
                    last_data2 = data2[-1000:]

                    print(f"\n===== –ü–æ—Å–ª–µ–¥–Ω–∏–µ {len(last_data1)} —Å—Ç—Ä–æ–∫ –ø–æ {ticker1} =====")
                    for record in last_data1:
                        print(record)
                    print(f"===== –ö–æ–Ω–µ—Ü –¥–∞–Ω–Ω—ã—Ö {ticker1} =====\n")

                    print(f"\n===== –ü–æ—Å–ª–µ–¥–Ω–∏–µ {len(last_data2)} —Å—Ç—Ä–æ–∫ –ø–æ {ticker2} =====")
                    for record in last_data2:
                        print(record)
                    print(f"===== –ö–æ–Ω–µ—Ü –¥–∞–Ω–Ω—ã—Ö {ticker2} =====\n")

                    data1, data2 = [], []
                    for record in last_data1:
                        data1.append(record[0])
                    for record in last_data2:
                        data2.append(record[0])
                    # –§—É–Ω–∫—Ü–∏—è –¥–ª—è –ø—Ä–µ–æ–±—Ä–∞–∑–æ–≤–∞–Ω–∏—è —Å–ø–∏—Å–∫–∞ —Å—Ç—Ä–æ–∫ –≤ —Å–ø–∏—Å–æ–∫ float
                    def convert_to_float(lst):
                        return [float(x.replace(',', '.')) for x in lst]
                    # –ö–æ–Ω–≤–µ—Ä—Ç–∞—Ü–∏—è —Å–ø–∏—Å–∫–æ–≤
                    arr1 = convert_to_float(data1)
                    arr2 = convert_to_float(data2)

                    # –í—ã—á–∏—Å–ª–µ–Ω–∏–µ –∫–æ—Ä—Ä–µ–ª—è—Ü–∏–∏ –ü–∏—Ä—Å–æ–Ω–∞
                    correlation = np.corrcoef(arr1, arr2)[0, 1]

                    print(f"–ö–æ—Ä—Ä–µ–ª—è—Ü–∏—è: {correlation}")

                    message = f"–í—ã–≤–µ–¥–µ–Ω—ã –ø–æ—Å–ª–µ–¥–Ω–∏–µ —Å—Ç—Ä–æ–∫–∏ –ø–æ {ticker1} –∏ {ticker2} –≤ –∫–æ–Ω—Å–æ–ª—å."

            except Exception as e:
                message = f"–û—à–∏–±–∫–∞: {e}"
        else:
            message = "–ü–æ–∂–∞–ª—É–π—Å—Ç–∞, –≤–≤–µ–¥–∏—Ç–µ –æ–±–∞ —Ç–∏–∫–µ—Ä–∞."

    return render(request, 'parserapp/correlation.html', {'message': message, 'correlation': correlation})
